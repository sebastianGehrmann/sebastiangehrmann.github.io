---
permalink: /
title: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am Technical Strategist for Responsible AI in the CTO office at Bloomberg where I develop and implement the vision and framework for Responsible AI at the company. My goal is to shape policies and practices to enable and facilitate the development of AI solutions that are trustworthy, transparent, and reliable.
Previously, as Head of NLP, I directed the development and adoption of language technology. Before joining Bloomberg, I was a researcher at Google working on evaluation of large language models. I hold a <a href="/files/gehrmann_dissertation.pdf" target="_blank">Ph.D. from Harvard University</a>.

_If you are interested in positions at Bloomberg, please check our <a href="https://www.bloomberg.com/company/values/tech-at-bloomberg/artificial-intelligence-ai/">AI careers page</a>._

# Research

My research interests include natural language generation, model evaluation, and interpretability. I particilarly like working on large multi-disciplinary collaborations, for example the <a href="https://gem-benchmark.com/" target="_blank">GEM benchmark</a>. I further was able to contribute to four LLM projects: PaLM, PaLM 2, BLOOM, and BloombergGPT.

You can find a full list of papers on my <a href="https://scholar.google.com/citations?hl=en&user=x6KQCV8AAAAJ">Google Scholar</a>.

# Selected Talks and Presentations

- <a href="https://www.youtube.com/watch?v=uyl-AqDF4ec" target="_blank">BloombergGPT: A Large Language Model for Finance</a> (Youtube), Synthetic Intelligence Forum, 2023
- <a href="files/Stanford NLP Seminar.pdf" target="_blank">Do we know what we don't know? The state of evaluation in NLP</a> (Slides), Stanford NLP Seminar, 2022
- <a href="/files/SIGGEN_GEMv2.pdf" target="_blank">Measuring the Quality of Language Generation Systems</a> (Slides), SIGGEN/SICSA Seminar, 2022
- <a href="/files/NewSum_21_Breaking_News.pdf" target="_blank">Itâ€™s time to fix evaluation
  of generated text</a> (Slides), Keynote at the Summarization Workshop at EMNLP 2021
- <a href="/files/acl_2020_interpretability_tutorial.pdf" target="_blank">Tutorial on Interpretability</a> (Slides) at ACL 2020 with Yonatan Belinkov and Ellie Pavlick

# Selected Press and Media

- <a href="https://aimagazine.com/articles/nlps-and-the-hurdles-halting-their-true-potential" target="_blank">NLPs and the Hurdles Halting Their True Potential</a>, AI Magazine, 2024
- <a href="https://www.huffpost.com/archive/in/entry/ai-tool-detect-computer-generated-text-fake-news-deepfakes_in_5d413037e4b01d8c978352fe?utm_hp_ref=in-homepage&guccounter=1" target="_blank">There's A New AI Tool That Can Spot Text Written By AI, Even When Humans Are Fooled</a>, Huffpost, 2019
- <a href="https://www.cnet.com/tech/computing/ai-now-can-spot-fake-news-generated-by-ai/" target="_blank">AI now can spot fake news generated by AI</a>, CNET, 2019
- <a href="https://venturebeat.com/ai/ibm-harvard-develop-tool-to-tackle-black-box-problem-in-ai-translation" target="_blank">IBM, Harvard develop tool to tackle black box problem in AI translation
  </a>, VentureBeat, 2018
