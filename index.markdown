---
layout: page
---

I am Head of NLP in the CTO office at Bloomberg, where I support the development of language technology across the company.
Formerly, I was a researcher at Google and I hold a <a href="/assets/files/gehrmann_dissertation.pdf" target="_blank">Ph.D. from Harvard</a>.

My research interests include natural language generation, model evaluation, and interpretability. I particilarly like working on large multi-disciplinary collaborations, for example the <a href="https://gem-benchmark.com/" target="_blank">GEM benchmark</a> for which we are frequently organizing workshops and are looking for participants.

You can find slides for a couple of my recent talks here:

- <a href="/assets/files/Stanford NLP Seminar.pdf" target="_blank">Do we know what we don't know? The state of evaluation in NLP</a>, Stanford NLP Seminar, 2022
- <a href="/assets/files/[SIGGEN_SICSA] GEMv2.pdf" target="_blank">Measuring the Quality of Language Generation Systems</a>, SIGGEN/SICSA Seminar, 2022
- <a href="/assets/files/gehrmann_dissertation.pdf" target="_blank">Itâ€™s time to fix evaluation
  of generated text</a>, Keynote at the Summarization Workshop at EMNLP 2021
- <a href="/assets/files/acl_2020_interpretability_tutorial.pdf" target="_blank">ACL 2020 Tutorial on Interpretability with Yonatan Belinkov and Ellie Pavlick</a>

<!-- You can find my full CV <a href="#" target="_blank">here</a>. -->
